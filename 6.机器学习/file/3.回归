回归：连续型数据

f(x)=w1x1+w2x2+...+wdxd+b  #w为权重[特征],b为偏置顶
一维～多维[数字,点,线,面]

线性回归：
    正规方程 数据大时 慢[不能解决过拟合的问题]
    梯度下降[大规模数据]
逻辑回归[只能解决二分类]：线性回归式子作为输入  而分类/也能得出概率
    sigmod:得出概率值[输出在0-1之间；阈值0.5]eg:预测 是否[假如正确结果是是]:预测是100%[损失率最小],预测否0%[损失率最大]
    损失率解决：见图
===================== 过拟合与欠拟合 ==================
欠拟合 学习的特征太少[限制条件太少]  交叉验证：训练集结果不好  测试集结果不好

过拟合 学习的特征太多[限制条件太多]  交叉验证：训练集结果好    测试集结果不好
    解决：进行特征选择，消除关联性大的特征(很难做)
         交叉验证(让所有数据都有过训练)
         正则化(将线性的系数趋近为0)[线性回归容易出现过拟合-使用l2正则化来解决 ][岭回归-带有正则化的线性回归]
            正则化调优：alpha(正则化力度[越大权重越趋近与0-见图])；coef_回归系数
                岭回归：回归得到的回归系数更可靠更符合实际,另外，能让估计参数的波动范围变小,变得更稳定。
                在存在病态数据偏多的研究中有较大的实用价值(将线性的系数趋近为0)